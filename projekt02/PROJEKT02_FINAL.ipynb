{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidzimniok/MPA-MLF/blob/main/projekt02/PROJEKT02_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sc6a23gWSU1p"
      },
      "outputs": [],
      "source": [
        "from PIL import Image #library for loading png files\n",
        "import glob           #library for multiple loading\n",
        "import csv            #library for loading csv file\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.optimizers import Adamax\n",
        "from keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "import re\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox7TMO1DjGSP",
        "outputId": "87ccba1a-919a-4f15-ddc9-ed94ad79e976"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#mount Gdrive and load train, test dataset and labels\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VugawczqjQdv"
      },
      "source": [
        "# UNZIP files on gdrive  !RUN only once!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUOGoT9-h64t"
      },
      "outputs": [],
      "source": [
        "# Path to the ZIP file on Google Drive\n",
        "zip_file_path = '/content/drive/MyDrive/Colab Notebooks/projekt02/train_data_unlabeled.zip'\n",
        "\n",
        "# Path to the folder where you want to extract the files\n",
        "extracted_folder_path = '/content/drive/MyDrive/Colab Notebooks/projekt02'\n",
        "\n",
        "# Unzip the file\n",
        "!unzip \"$zip_file_path\" -d \"$extracted_folder_path\"\n",
        "\n",
        "print(\"Extraction completed successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-dWbmFmVxel"
      },
      "outputs": [],
      "source": [
        "# Path to the ZIP file on Google Drive\n",
        "zip_file_path = '/content/drive/MyDrive/Colab Notebooks/projekt02/test_data_unlabeled.zip'\n",
        "\n",
        "# Path to the folder where you want to extract the files\n",
        "extracted_folder_path = '/content/drive/MyDrive/Colab Notebooks/projekt02'\n",
        "\n",
        "# Unzip the file\n",
        "!unzip \"$zip_file_path\" -d \"$extracted_folder_path\"\n",
        "\n",
        "print(\"Extraction completed successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siHJPEuzjVNY"
      },
      "source": [
        "# Load test and train datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpejYmZpPyo0"
      },
      "outputs": [],
      "source": [
        "#function to get number of measure from the path\n",
        "def extract_number(filename):\n",
        "    filename = filename[48:]\n",
        "    return int(re.search(r'\\d+', filename).group())\n",
        "\n",
        "#function for loading dataset from Gdrive\n",
        "def load_dataset(path):\n",
        "  data=[]\n",
        "\n",
        "  file_paths=glob.glob(path + \"/*.png\")\n",
        "  file_paths=sorted(file_paths, key=extract_number)\n",
        "\n",
        "  for im_path in file_paths:\n",
        "      im = Image.open(im_path).convert('L')\n",
        "      data.append(im)\n",
        "\n",
        "  image_arr=[np.array(img) for img in data]\n",
        "  image_arr=np.array(image_arr)/255.0\n",
        "  return image_arr\n",
        "\n",
        "train_data=load_dataset(\"/content/drive/MyDrive/Colab Notebooks/projekt02/train_data_unlabeled\")\n",
        "test_data=load_dataset(\"/content/drive/MyDrive/Colab Notebooks/projekt02/test_data_unlabeled\")\n",
        "\n",
        "labels=[]\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/projekt02/y_train.csv\", 'r', newline='', encoding='utf-8') as csvfile:\n",
        "    csvreader = csv.reader(csvfile, delimiter=',')\n",
        "    next(csvreader) #skip header of column\n",
        "    #save data to the list\n",
        "    for row in csvreader:\n",
        "        labels.append(row[1])\n",
        "\n",
        "y_labels=np.array(labels)\n",
        "y_labels = to_categorical(y_labels, num_classes=4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data augmentation - not used\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_data, y_labels, test_size=0.2)\n",
        "\n",
        "X_train = X_train.reshape(-1, 45, 51, 1)\n",
        "X_test = X_test.reshape(-1, 45, 51, 1)\n",
        "\n",
        "datagen = ImageDataGenerator(featurewise_center=False,\n",
        "                            samplewise_center=False,\n",
        "                            featurewise_std_normalization=False,\n",
        "                            samplewise_std_normalization=False,\n",
        "                            zca_whitening=False,\n",
        "                            rotation_range=1,\n",
        "                            width_shift_range=0.1,\n",
        "                            height_shift_range=0.1,\n",
        "                            horizontal_flip=False,\n",
        "                            vertical_flip=False)\n",
        "\n",
        "datagen.fit(X_train)\n",
        "\n",
        "#logaritmic scaling\n",
        "train_data = np.log(train_data + 1)\n",
        "train_data = train_data / np.max(train_data)"
      ],
      "metadata": {
        "id": "3NbaTexcBa9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7LmNmpDjbnA"
      },
      "source": [
        "# Create NN model and train the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6I_syfIbeK3L"
      },
      "outputs": [],
      "source": [
        "#create NN model\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(45, 51, 1)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='sigmoid', kernel_initializer='he_uniform'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(256, activation='sigmoid', kernel_initializer='he_uniform'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(128, activation='sigmoid', kernel_initializer='he_uniform'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(64, activation='sigmoid', kernel_initializer='he_uniform'))\n",
        "\n",
        "model.add(Dense(4, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VyKICBwIe_qm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "38fd9334-0a3b-4193-fa11-81639f3f8fe4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'ReduceLROnPlateau' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-f6dd1e3ab68c>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#model.compile(loss='categorical_crossentropy',optimizer=optimizer,metrics=['accuracy'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mreduce_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ReduceLROnPlateau' is not defined"
          ]
        }
      ],
      "source": [
        "optimizer=Adamax(learning_rate=0.001)\n",
        "#model.compile(loss='categorical_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
        "early_stopping=EarlyStopping(monitor='val_accuracy',patience=5,restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgRlZjTSfOKw"
      },
      "outputs": [],
      "source": [
        "history=model.fit(train_data,y_labels,validation_split=0.2,epochs=100,callbacks=[early_stopping,reduce_lr])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fitting with augmented data - not used\n",
        "history = model.fit(datagen.flow(X_train, y_train),  # Training data with data augmentation\n",
        "                    #validation_data=datagen.flow(X_test.astype('float32') / 255.0, to_categorical(y_test), batch_size=512),\n",
        "                    validation_data=datagen.flow(X_test, y_test),\n",
        "                    epochs=30)"
      ],
      "metadata": {
        "id": "RuEQJHp1Bt7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWHwGhIvKwiH"
      },
      "outputs": [],
      "source": [
        "#evaluate the model accurancy\n",
        "score=model.evaluate(train_data,y_labels,verbose=0)\n",
        "print('Test loss:',score[0])\n",
        "print(f'Test accuracy: {score[1]*100} %')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyhF73FjK09q"
      },
      "outputs": [],
      "source": [
        "#plot loss and accurancy\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRNi55O3jzQC"
      },
      "source": [
        "# Save trained network and predict data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07cU_H1WMfId",
        "outputId": "de90c592-1805-479f-9368-ba403b9c490b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to Google Drive.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "path_model=\"model_09042024.h5\"\n",
        "\n",
        "#save trained model to the Gdrive\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/projekt02/models/'+path_model)\n",
        "print(\"Model saved to Google Drive.\")\n",
        "\n",
        "#load model from Gdrive\n",
        "#model=load_model(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p16Jbs9wM_I5",
        "outputId": "81972272-dd0e-470f-a2eb-a22e0386c18e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "150/150 [==============================] - 13s 87ms/step\n"
          ]
        }
      ],
      "source": [
        "#apply model to the provided dataset\n",
        "predictions=model.predict(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jn-xZ3VOSMMc",
        "outputId": "d9644f4a-29ce-4a34-f2f2-cfc6a4f3f10c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions saved to CSV file: /content/drive/MyDrive/Colab Notebooks/projekt02/model_09042024_1.csv\n"
          ]
        }
      ],
      "source": [
        "#convert predictions (probability of number of persons in room) to the index = number of persons\n",
        "predicted=np.argmax(predictions,axis=1)\n",
        "\n",
        "prediction_file=\"model_09042024_1.csv\"\n",
        "\n",
        "csv_file_path='/content/drive/MyDrive/Colab Notebooks/projekt02/outputs/'+prediction_file\n",
        "with open(csv_file_path, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['id', 'target'])\n",
        "    for idx, prediction in enumerate(predicted):\n",
        "        writer.writerow([idx, prediction])\n",
        "\n",
        "print(f\"Predictions saved to CSV file: {csv_file_path}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}